# ML Model Development Pipeline
## **Data Collection**
Welcome to the data_collection folder in your ML model development pipeline. 

## **Purpose**: This folder houses the scripts and resources responsible for collecting and storing raw data into the ML pipeline. The collected data is the foundation upon which all subsequent steps, such as feature engineering and model training, are built.

## How to Use
1. **Source the Data**: Describe where the data comes from (e.g., an API, a public dataset, etc.). If there are any authentication steps or rate limits, mention them here.



```python
   python data_collection.py
   ```



2. **Run the Script**: Open the 'data_collection.py' script using a Python interpreter. Make sure all dependencies are installed (you can list them here or in a requirements.txt file).
  
   For example:
   
   

```python
   jupyter notebook baseline.ipynb
   ```


3. **Check the Data Format**: Ensure the collected data is stored in the correct format for the data pre-processing step. For example, the data might need to be in a CSV file with specific column headers.



## Contents
- **'data_collection.py'**: The main Python script for data collection.
- **'baseline.ipynb'**: A Jupyter Notebook guide to data collection.
- **'README.md'**: This file, providing an overview of the data collection module.

 